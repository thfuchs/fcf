% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/tune_keras_rnn.R
\name{tune_keras_rnn}
\alias{tune_keras_rnn}
\title{Tune recurrent neural network with Keras functional API and Bayes
Optimization and select best performing model}
\usage{
tune_keras_rnn(
  data,
  model_type,
  cv_setting,
  tuning_bounds,
  col_id = NULL,
  col_date = "index",
  col_value = "value",
  frequency = 4,
  multiple_h = NULL,
  level = 95,
  test_dropout = 0.1,
  save_model = NULL,
  save_model_id = NULL
)
}
\arguments{
\item{data}{Univariate time series (data.frame) with date and value column,
specified in \code{col_date} and \code{col_value}}

\item{model_type}{One of "simple", "gru" or "lstm"}

\item{cv_setting}{list of "periods_train", "periods_val", "periods_test" and
"skip_span" for \link[rsample]{rolling_origin}}

\item{tuning_bounds}{list of tuning parameters - see section "Tuning Bounds"}

\item{col_id}{Optional ID column in \code{data}, default to "ticker"}

\item{col_date}{Date column in \code{data}, default to "index"}

\item{col_value}{Value column in \code{data}, default to "value"}

\item{frequency}{time series frequency, e.g. 4 for quarters and 12 for months}

\item{multiple_h}{NULL if forecast horizon equals cv_setting$n_test, else
named list of forecast horizons for accuracy measures}

\item{level}{level for prediction interval in percentage}

\item{test_dropout}{specify dropout-rate during testing for prediction
interval}

\item{save_model}{Automatically save tuned models? Specify NULL for No or
character vector with path to directory for yes}

\item{save_model_id}{optional id for model filename}
}
\value{
list of "results" and "min_params"
}
\description{
Tune recurrent neural network with Keras functional API and Bayes
Optimization and select best performing model
}
\section{Tuning Bounds}{

The following parameters are (currently) available for tuning.
\itemize{
\item lag_1 (integer(2)) lower bounds
\item lag_2 (integer(2)) upper bounds
\item n_units (integer(2)) lower and upper bound for rnn units (cells)
\item n_epochs (integer(2)) lower and upper bound for epochs
\item optimizer_type (integer(2)) lower and upper bound for optimizer:
1 = "rmsprop", 2 = "adam", 3 = "adagrad"
\item dropout = (numeric(2)) lower and upper bound for dropout rate
\item recurrent_dropout = (numeric(2)) lower and upper bound for recurrent dropout rate
\item learning_rate = (numeric(2)) lower and upper bound for learning rate
}
}

