% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/tune_keras_rnn_bayesoptim.R
\name{tune_keras_rnn_bayesoptim}
\alias{tune_keras_rnn_bayesoptim}
\title{Tune recurrent neural network with Keras functional API and Bayes
Optimization to select best performing model}
\usage{
tune_keras_rnn_bayesoptim(
  data,
  model_type,
  cv_setting,
  tuning_bounds,
  col_id = NULL,
  col_date = "index",
  col_value = "value",
  save = NULL,
  save_id = NULL
)
}
\arguments{
\item{data}{Univariate time series (data.frame) with date and value column,
specified in \code{col_date} and \code{col_value}}

\item{model_type}{One of "simple", "gru" or "lstm"}

\item{cv_setting}{list of "periods_train", "periods_val", "periods_test" and
"skip_span" for \link[rsample]{rolling_origin}}

\item{tuning_bounds}{list of tuning parameters - see section "Tuning Bounds"}

\item{col_id}{Optional ID column in \code{data}, default to "ticker"}

\item{col_date}{Date column in \code{data}, default to "index"}

\item{col_value}{Value column in \code{data}, default to "value"}

\item{save}{Automatically save tuning results? Specify NULL if not or
character vector with path to directory for yes}

\item{save_id}{optional id for model filename}
}
\value{
list of Bayes Optimization results per split
}
\description{
Tune recurrent neural network with Keras functional API and Bayes
Optimization to select best performing model
}
\section{Tuning Bounds}{

The following parameters are (currently) available for tuning.
\itemize{
\item lag_1 (integer(2)) lower bounds
\item lag_2 (integer(2)) upper bounds
\item n_units (integer(2)) lower and upper bound for rnn units (cells)
\item n_epochs (integer(2)) lower and upper bound for epochs
\item optimizer_type (integer(2)) lower and upper bound for optimizer:
1 = "rmsprop", 2 = "adam", 3 = "adagrad"
\item dropout = (numeric(2)) lower and upper bound for dropout rate
\item recurrent_dropout = (numeric(2)) lower and upper bound for recurrent dropout rate
\item learning_rate = (numeric(2)) lower and upper bound for learning rate
}
}

