% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/tune_keras_rnn_bayesoptim.R
\name{tune_keras_rnn_bayesoptim}
\alias{tune_keras_rnn_bayesoptim}
\title{Automatic cross-validated tuning of recurrent neural networks for time series
data}
\usage{
tune_keras_rnn_bayesoptim(
  data,
  model_type,
  cv_setting,
  tuning_bounds = list(),
  col_id = NULL,
  col_date = "index",
  col_value = "value",
  save = NULL,
  save_id = NULL
)
}
\arguments{
\item{data}{Univariate time series (data.frame) with date and value column,
specified in \code{col_date} and \code{col_value}}

\item{model_type}{One of "simple", "gru" or "lstm"}

\item{cv_setting}{list of "periods_train", "periods_val", "periods_test" and
"skip_span" for \link[rsample]{rolling_origin}}

\item{tuning_bounds}{list of tuning parameters - see section "Tuning Bounds"}

\item{col_id}{Optional ID column in \code{data}, default to "ticker"}

\item{col_date}{Date column in \code{data}, default to "index"}

\item{col_value}{Value column in \code{data}, default to "value"}

\item{save}{Automatically save tuning results? Specify NULL if not or
character vector with path to directory for yes}

\item{save_id}{optional character id for model filename}
}
\value{
list of Bayes Optimization results per split
}
\description{
Tune recurrent neural network with Keras functional API and Bayes
Optimization to select best performing model
}
\section{Tuning Bounds}{

The following parameters are (currently) available for tuning.\cr
\itemize{
\item lag_1 (integer(2)) lower bounds - default \code{c(1L, 2L)}
\item lag_2 (integer(2)) upper bounds - default \code{c(1L, 2L)}
\item n_units (integer(2)) lower and upper bound for rnn units (cells) - default \code{c(8L, 32L)}
\item n_epochs (integer(2)) lower and upper bound for epochs - default \code{c(20L, 50L)}
\item optimizer_type (integer(2)) lower and upper bound for optimizer:
1 = "rmsprop", 2 = "adam", 3 = "adagrad" - default \code{c(1L, 3L)}
\item dropout = (numeric(2)) lower and upper bound for dropout rate - default \code{c(0, 0.5)}
\item recurrent_dropout = (numeric(2)) lower and upper bound for recurrent dropout rate - default \code{c(0, 0.5)}
\item learning_rate = (numeric(2)) lower and upper bound for learning rate - default \code{c(0.001, 0.01)}
Keep attention to the correct type (numeric length 2 / integer length 2).
All bounds are to be set, otherwise default serves as fallback.
}
}

\examples{
\dontrun{
apple <- tsRNN::DT_apple

cv_setting <- list(
  periods_train = 90,
  periods_val = 10,
  periods_test = 10,
  skip_span = 5
)

bayes <- tune_keras_rnn_bayesoptim(apple, model_type = "simple", cv_setting)
bayes
}
}
\seealso{
Other RNN tuning by Keras: 
\code{\link{tune_keras_rnn_eval}()},
\code{\link{tune_keras_rnn_predict}()}
}
\concept{RNN tuning by Keras}
