% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/tune_keras_sequential.R
\name{tune_keras_sequential}
\alias{tune_keras_sequential}
\title{Tune keras basic model with Bayes Optimization and select best performing
model}
\usage{
tune_keras_sequential(
  data,
  model_type,
  cv_setting,
  tuning_bounds,
  frequency = 4,
  iterations = 2000,
  multiple_h = NULL,
  level = 95,
  test_dropout = 0.1
)
}
\arguments{
\item{data}{Univariate time series (data.frame) with columns index and value}

\item{model_type}{One of "basic", "gru" or "lstm"}

\item{cv_setting}{list of "periods_train", "periods_val", "periods_test" and
"skip_span" for \link[rsample]{rolling_origin}}

\item{tuning_bounds}{list of tuning parameters - see section "Tuning Bounds"}

\item{frequency}{time series frequency, e.g. 4 for quarters and 12 for months}

\item{iterations}{number of iterations for dropout-based prediction interval}

\item{multiple_h}{NULL if forecast horizon equals cv_setting$n_test, else
named list of forecast horizons for accuracy measures}

\item{level}{level for prediction interval in percentage}

\item{test_dropout}{specify dropout-rate during testing for prediction
interval}
}
\value{
list of "results" and "min_params"
}
\description{
Tune keras basic model with Bayes Optimization and select best performing
model
}
\section{Tuning Bounds}{

The following parameters are (currently) available for tuning.
\itemize{
\item lag_1 (integer(2)) lower bounds
\item lag_2 (integer(2)) upper bounds
\item n_units (integer(2)) lower and upper bound for rnn units (cells)
\item n_epochs (integer(2)) lower and upper bound for epochs
\item optimizer_type (integer) 1 = "rmsprop", 2 = "adam"
\item dropout = (numeric(2)) lower and upper bound for dropout rate
\item recurrent_dropout = (numeric(2)) lower and upper bound for recurrent dropout rate
\item learning_rate = (numeric(2)) lower and upper bound for learning rate
}
}

